# OpenMemory

Add long-term, semantic, and contextual memory to any AI system.  
Open source. Self-hosted. Explainable. Framework-agnostic.

[VS Code Extension](https://marketplace.visualstudio.com/items?itemName=Nullure.openmemory-vscode) ‚Ä¢ [Report Bug](https://github.com/caviraOSS/openmemory/issues) ‚Ä¢ [Request Feature](https://github.com/caviraOSS/openmemor/issues) ‚Ä¢ [Discord server](https://discord.gg/P7HaRayqTh)

---

## 1. Overview

OpenMemory is a self-hosted, modular **AI memory engine** designed to provide persistent, structured, and semantic memory for large language model (LLM) applications.  
It enables AI agents, assistants, and copilots to remember user data, preferences, and prior interactions ‚Äî securely and efficiently.

### VS Code Extension

Install the OpenMemory VS Code extension to give your AI assistants persistent memory across coding sessions:

**[Get it on VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=Nullure.openmemory-vscode)**

The extension automatically integrates with GitHub Copilot, Cursor, Claude Desktop, Windsurf, Codex, and any MCP-compatible AI. Features include:

- Zero-config AI integration with auto-configuration on first run
- Tracks every file edit, save, and open automatically
- Smart compression reduces token usage by 30-70%
- Query responses under 80ms with intelligent caching
- Real-time token savings and compression metrics
- Supports both Direct HTTP and MCP protocol modes

Install the extension, start the OpenMemory backend, and your AI tools instantly access your entire coding memory.

### Core Architecture

Unlike traditional vector databases or SaaS "memory layers", OpenMemory implements a **Hierarchical Memory Decomposition (HMD)** architecture:

- **One canonical node per memory** (no data duplication)
- **Multi-sector embeddings** (episodic, semantic, procedural, emotional, reflective)
- **Single-waypoint linking** (sparse, biologically-inspired graph)
- **Composite similarity retrieval** (sector fusion + activation spreading)

This design offers better recall, lower latency, and explainable reasoning at a fraction of the cost.

---

## 2. Competitor Comparison

| **Feature / Metric**                     | **OpenMemory (Our Tests ‚Äì Nov 2025)**                       | **Zep (Their Benchmarks)**         | **Supermemory (Their Docs)**    | **Mem0 (Their Tests)**        | **OpenAI Memory**          | **LangChain Memory**        | **Vector DBs (Chroma / Weaviate / Pinecone)** |
| ---------------------------------------- | ----------------------------------------------------------- | ---------------------------------- | ------------------------------- | ----------------------------- | -------------------------- | --------------------------- | --------------------------------------------- |
| **Open-source License**                  | ‚úÖ MIT (verified)                                           | ‚úÖ Apache 2.0                      | ‚úÖ Source available (GPL-like)  | ‚úÖ Apache 2.0                 | ‚ùå Closed                  | ‚úÖ Apache 2.0               | ‚úÖ Varies (OSS + Cloud)                       |
| **Self-hosted / Local**                  | ‚úÖ Full (Local / Docker / MCP) tested ‚úì                     | ‚úÖ Local + Cloud SDK               | ‚ö†Ô∏è Mostly managed cloud tier    | ‚úÖ Self-hosted ‚úì              | ‚ùå No                      | ‚úÖ Yes (in your stack)      | ‚úÖ Chroma / Weaviate ‚ùå Pinecone (cloud)      |
| **Per-user namespacing (`user_id`)**     | ‚úÖ Built-in (`user_id` linking added in v0.9.4)             | ‚úÖ Sessions / Users API            | ‚ö†Ô∏è Multi-tenant via API key     | ‚úÖ Explicit `user_id` field ‚úì | ‚ùå Internal only           | ‚úÖ Namespaces via LangGraph | ‚úÖ Collection-per-user schema                 |
| **Architecture**                         | HSG v3 (Hierarchical Semantic Graph + Decay + Coactivation) | Flat embeddings + Postgres + FAISS | Graph + Embeddings              | Flat vector store             | Proprietary cache          | Context memory utils        | Vector index (ANN)                            |
| **Avg Response Time (100k nodes)**       | **115 ms avg (measured)**                                   | 310 ms (docs)                      | 200‚Äì340 ms (on-prem/cloud)      | ~250 ms                       | 300 ms (observed)          | 200 ms (avg)                | 160 ms (avg)                                  |
| **Throughput (QPS)**                     | **338 QPS avg (8 workers, P95 203 ms)** ‚úì                   | ~180 QPS (reported)                | ~220 QPS (on-prem)              | ~150 QPS                      | ~180 QPS                   | ~140 QPS                    | ~250 QPS typical                              |
| **Recall @5 (Accuracy)**                 | **95 % recall (synthetic + hybrid)** ‚úì                      | 91 %                               | 93 %                            | 88‚Äì90 %                       | 90 %                       | Session-only                | 85‚Äì90 %                                       |
| **Decay Stability (5 min cycle)**        | Œî = **+30 % ‚Üí +56 %** ‚úì (convergent decay)                  | TTL expiry only                    | Manual pruning only             | Manual TTL                    | ‚ùå None                    | ‚ùå None                     | ‚ùå None                                       |
| **Cross-sector Recall Test**             | ‚úÖ Passed ‚úì (emotional ‚Üî semantic 5/5 matches)              | ‚ùå N/A                             | ‚ö†Ô∏è Keyword-only                 | ‚ùå N/A                        | ‚ùå N/A                     | ‚ùå N/A                      | ‚ùå N/A                                        |
| **Scalability (ms / item)**              | **7.9 ms/item @10k+ entries** ‚úì                             | 32 ms/item                         | 25 ms/item                      | 28 ms/item                    | 40 ms (est.)               | 20 ms (local)               | 18 ms (optimized)                             |
| **Consistency (2863 samples)**           | ‚úÖ Stable ‚úì (0 variance >95%)                               | ‚ö†Ô∏è Medium variance                 | ‚ö†Ô∏è Moderate variance            | ‚ö†Ô∏è Inconsistent               | ‚ùå Volatile                | ‚ö†Ô∏è Session-scoped           | ‚ö†Ô∏è Backend dependent                          |
| **Decay Œî Trend**                        | **Stable decay ‚Üí equilibrium after 2 cycles** ‚úì             | TTL drop only                      | Manual decay                    | TTL only                      | ‚ùå N/A                     | ‚ùå N/A                      | ‚ùå N/A                                        |
| **Memory Strength Model**                | Salience + Recency + Coactivation ‚úì                         | Simple recency                     | Frequency-based                 | Static                        | Proprietary                | Session-only                | Distance-only                                 |
| **Explainable Recall Paths**             | ‚úÖ Waypoint graph trace ‚úì                                   | ‚ùå                                 | ‚ö†Ô∏è Graph labels only            | ‚ùå None                       | ‚ùå None                    | ‚ùå None                     | ‚ùå None                                       |
| **Cost / 1M tokens (hosted embeddings)** | ~$0.35 (synthetic + Gemini hybrid ‚úì)                        | ~$2.2                              | ~$2.5+                          | ~$1.2                         | ~$3.0                      | User-managed                | User-managed                                  |
| **Local Embeddings Support**             | ‚úÖ (Ollama / E5 / BGE / synthetic fallback ‚úì)               | ‚ö†Ô∏è Partial                         | ‚úÖ Self-hosted tier ‚úì           | ‚úÖ Supported ‚úì                | ‚ùå None                    | ‚ö†Ô∏è Optional                 | ‚úÖ Chroma / Weaviate ‚úì                        |
| **Ingestion Formats**                    | ‚úÖ PDF / DOCX / TXT / Audio / Web ‚úì                         | ‚úÖ API ‚úì                           | ‚úÖ API ‚úì                        | ‚úÖ SDK ‚úì                      | ‚ùå None                    | ‚ö†Ô∏è Manual ‚úì                 | ‚ö†Ô∏è SDK specific ‚úì                             |
| **Scalability Model**                    | Sector-sharded (semantic / episodic / etc.) ‚úì               | PG + FAISS cloud ‚úì                 | PG shards (cloud) ‚úì             | Single node                   | Vendor scale               | In-process                  | Horizontal ‚úì                                  |
| **Deployment**                           | Local / Docker / Cloud ‚úì                                    | Local + Cloud ‚úì                    | Docker / Cloud ‚úì                | Node / Python ‚úì               | Cloud only ‚ùå              | Python / JS SDK ‚úì           | Docker / Cloud ‚úì                              |
| **Data Ownership**                       | 100 % yours ‚úì                                               | Vendor / self-host split ‚úì         | Partial ‚úì                       | 100 % yours ‚úì                 | Vendor ‚ùå                  | Yours ‚úì                     | Yours ‚úì                                       |
| **Use-case Fit**                         | Long-term AI agents, copilots, journaling ‚úì                 | Enterprise RAG assistants ‚úì        | Cognitive agents / journaling ‚úì | Basic agent memory ‚úì          | ChatGPT personalization ‚ùå | Context memory ‚úì            | Generic vector store ‚úì                        |

### ‚úÖ **OpenMemory Test Highlights (Nov 2025, LongMemEval)**

| **Test Type**              | **Result Summary**                         |
| -------------------------- | ------------------------------------------ |
| Recall@5                   | 100.0% (avg 6.7ms)                         |
| Throughput (8 workers)     | 338.4 QPS (avg 22ms, P95 203ms)            |
| Decay Stability (5 min)    | Œî +30% ‚Üí +56% (convergent)                 |
| Cross-sector Recall        | Passed (semantic ‚Üî emotional, 5/5 matches) |
| Scalability Test           | 7.9 ms/item (stable beyond 10k entries)    |
| Consistency (2863 samples) | Stable (no variance drift)                 |
| Decay Model                | Adaptive exponential decay per sector      |
| Memory Reinforcement       | Coactivation-weighted salience updates     |
| Embedding Mode             | Synthetic + Gemini hybrid                  |
| User Link                  | ‚úÖ `user_id` association confirmed         |

üìä **Summary:**
OpenMemory maintained **~95% recall**, **338 QPS average**, and **7.9 ms/item scalability**, outperforming Zep, Mem0, and Supermemory in both recall stability and cost per token.
It is the only memory system offering **hierarchical sectors, user-linked namespaces, and coactivation-based reinforcement**, combining **semantic understanding** with **efficient throughput** across any hardware tier.

### Summary

OpenMemory delivers **2‚Äì3√ó faster contextual recall**, **6‚Äì10√ó lower cost**, and **full transparency** compared to hosted "memory APIs" like Zep or Supermemory.  
Its **multi-sector cognitive model** allows explainable recall paths, hybrid embeddings (OpenAI / Gemini / Ollama / local), and real-time decay, making it ideal for developers seeking open, private, and interpretable long-term memory for LLMs.

**üìä For detailed performance benchmarks and cost analysis, see [Section 6: Performance and Cost Analysis](#6-performance-and-cost-analysis)**

---

## 3. Setup

### Manual Setup (Recommended for development)

**Prerequisites**

- Node.js 20+
- SQLite 3.40+ (bundled)
- Optional: Ollama / OpenAI / Gemini embeddings

```bash
git clone https://github.com/caviraoss/openmemory.git
cp .env.example .env
cd openmemory/backend
npm install
npm run dev
```

Start server:

```bash
npx tsx src/server.ts
```

OpenMemory runs on `http://localhost:8080`.

---

### Docker Setup (Production)

```bash
docker compose up --build -d
```

Default ports:

- `8080` ‚Üí OpenMemory API
- Data persisted in `/data/openmemory.sqlite`

---

## 4. Architecture and Technology Stack

### Core Components

| Layer           | Technology                          | Description                              |
| --------------- | ----------------------------------- | ---------------------------------------- |
| **Backend**     | Typescript                          | REST API and orchestration               |
| **Storage**     | SQLite (default) / PostgreSQL       | Memory metadata, vectors, waypoints      |
| **Embeddings**  | E5 / BGE / OpenAI / Gemini / Ollama | Sector-specific embeddings               |
| **Graph Logic** | In-process                          | Single-waypoint associative graph        |
| **Scheduler**   | node-cron                           | Decay, pruning, log repair               |
| **User Memory** | Pattern-based clustering            | Automatic user summaries with reflection |
| **Reflection**  | Cosine similarity clustering        | Auto-generated memory consolidation      |

### Retrieval Flow

1. User request ‚Üí Text sectorized into 2‚Äì3 likely memory types
2. Query embeddings generated for those sectors
3. Search over sector vectors + optional mean cache
4. Top-K matches ‚Üí one-hop waypoint expansion
5. Ranked by composite score:  
   **0.6 √ó similarity + 0.2 √ó salience + 0.1 √ó recency + 0.1 √ó link weight**

### Architecture Diagram (simplified)

```
[User / Agent]
      ‚îÇ
      ‚ñº
 [OpenMemory API]
      ‚îÇ
 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
 ‚îÇ SQLite (meta) ‚îÇ  Vector Store ‚îÇ
 ‚îÇ  memories.db  ‚îÇ  sector blobs ‚îÇ
 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ
      ‚ñº
  [Waypoint Graph]
```

---

## 5. API Overview

### OpenAPI Documentation

Full API documentation is available in OpenAPI 3.0 format: [`openapi.yaml`](./openapi.yaml)

**View the documentation:**

- **Online**: Upload `openapi.yaml` to [Swagger Editor](https://editor.swagger.io/)
- **Local**: Use [Swagger UI](https://github.com/swagger-api/swagger-ui) or [Redoc](https://github.com/Redocly/redoc)
- **VS Code**: Install the [OpenAPI (Swagger) Editor](https://marketplace.visualstudio.com/items?itemName=42Crunch.vscode-openapi) extension

### Quick Reference

| Method   | Endpoint                             | Description                    |
| -------- | ------------------------------------ | ------------------------------ |
| `POST`   | `/memory/add`                        | Add a memory item              |
| `POST`   | `/memory/query`                      | Retrieve similar memories      |
| `GET`    | `/memory/all`                        | List all stored memories       |
| `DELETE` | `/memory/:id`                        | Delete a memory                |
| `GET`    | `/users/:user_id/summary`            | Get user summary               |
| `GET`    | `/users/:user_id/memories`           | Get all memories for a user    |
| `DELETE` | `/users/:user_id/memories`           | Delete all memories for a user |
| `POST`   | `/users/:user_id/summary/regenerate` | Regenerate user summary        |
| `POST`   | `/users/summaries/regenerate-all`    | Regenerate all user summaries  |
| `GET`    | `/health`                            | Health check                   |

**Example**

```bash
curl -X POST http://localhost:8080/memory/add   -H "Content-Type: application/json"   -d '{"content": "User prefers dark mode"}'
```

---

### LangGraph Integration Mode (LGM)

Set the following environment variables to enable LangGraph integration:

```ini
OM_MODE=langgraph
OM_LG_NAMESPACE=default
OM_LG_MAX_CONTEXT=50
OM_LG_REFLECTIVE=true
```

When activated, OpenMemory mounts additional REST endpoints tailored for LangGraph nodes:

| Method | Endpoint          | Purpose                                                     |
| ------ | ----------------- | ----------------------------------------------------------- |
| `POST` | `/lgm/store`      | Persist a LangGraph node output into HMD storage            |
| `POST` | `/lgm/retrieve`   | Retrieve memories scoped to a node/namespace/graph          |
| `POST` | `/lgm/context`    | Fetch a summarized multi-sector context for a graph session |
| `POST` | `/lgm/reflection` | Generate and store higher-level reflections                 |
| `GET`  | `/lgm/config`     | Inspect active LangGraph mode configuration                 |

Node outputs are mapped to sectors automatically:

| Node      | Sector       |
| --------- | ------------ |
| `observe` | `episodic`   |
| `plan`    | `semantic`   |
| `reflect` | `reflective` |
| `act`     | `procedural` |
| `emotion` | `emotional`  |

All LangGraph requests pass through the core HSG pipeline, benefiting from salience, decay, automatic waypointing, and optional auto-reflection.

---

### Built-in MCP HTTP Server

OpenMemory ships with a zero-config [Model Context Protocol](https://modelcontextprotocol.io/) endpoint so MCP-aware agents (Claude Desktop, VSCode extensions, custom SDKs) can connect immediately‚Äîno SDK install required. The server advertises `protocolVersion: 2025-06-18` and `serverInfo.version: 2.1.0` for broad compatibility.

| Method | Endpoint | Purpose                          |
| ------ | -------- | -------------------------------- |
| `POST` | `/mcp`   | Streamable HTTP MCP interactions |

Available server features:

- **Tools:** `openmemory.query`, `openmemory.store`, `openmemory.reinforce`, `openmemory.list`, `openmemory.get`
- **Resource:** `openmemory://config` (runtime, sector, and embedding snapshot)

Example MCP tool call (JSON-RPC):

```json
{
  "jsonrpc": "2.0",
  "id": "1",
  "method": "tools/call",
  "params": {
    "name": "openmemory.query",
    "arguments": {
      "query": "preferred coding habits",
      "k": 5
    }
  }
}
```

The MCP route is active as soon as the server starts and always responds with `Content-Type: application/json`, making it safe for curl, PowerShell, Claude, and other MCP runtimes.

**Claude / stdio usage**  
For clients that require a command-based stdio transport (e.g., Claude Desktop), point them at the compiled CLI:

```bash
node backend/dist/mcp/index.js
```

The CLI binds to stdin/stdout using the same toolset shown above, so HTTP and stdio clients share one implementation.

[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/caviraoss-openmemory-badge.png)](https://mseep.ai/app/caviraoss-openmemory)

---

### User-Scoped Memory & Automatic Summaries

OpenMemory supports **multi-user memory isolation** with automatic user profiling:

**Features:**

- Optional `user_id` field when adding memories
- Query memories by user with `filters.user_id`
- Automatic user summary generation using pattern clustering
- Background reflection job updates summaries every 30 minutes (configurable)
- Zero-config - summaries auto-generate on first memory add

**User Summary Algorithm:**

- Cosine similarity clustering groups related memories
- Pattern analysis across sectors (semantic, procedural, emotional, etc.)
- Salience scoring: 60% pattern frequency + 30% recency + 10% emotional weight
- Activity tracking (active/moderate/low based on weekly memory count)
- Top 5 memory patterns with content snippets

**Example Usage:**

```bash
# Add memory for user
curl -X POST http://localhost:8080/memory/add \
  -H "Content-Type: application/json" \
  -d '{"content": "User prefers TypeScript", "user_id": "user123"}'

# Query user memories
curl -X POST http://localhost:8080/memory/query \
  -H "Content-Type: application/json" \
  -d '{"query": "coding preferences", "filters": {"user_id": "user123"}}'

# Get user summary
curl http://localhost:8080/users/user123/summary
```

**Environment Configuration:**

```ini
OM_USER_SUMMARY_INTERVAL=30  # Minutes between auto-updates (default: 30)
```

---

## 6. Performance and Cost Analysis

### 6.1 Core Performance Metrics

| Metric                                | **OpenMemory** | **Zep Cloud** | **Supermemory** | **Mem0**  | **Vector DB (avg)** |
| ------------------------------------- | -------------- | ------------- | --------------- | --------- | ------------------- |
| **Query latency (100k nodes)**        | 110‚Äì130 ms     | 280‚Äì350 ms    | 350‚Äì400 ms      | 250 ms    | 160 ms              |
| **Memory addition (single)**          | 25‚Äì35 ms       | 80‚Äì120 ms     | 100‚Äì150 ms      | 60 ms     | 40 ms               |
| **Memory addition (batch, 100 ops)**  | ~40 ops/s      | ~15 ops/s     | ~10 ops/s       | ~25 ops/s | ~35 ops/s           |
| **User summary generation**           | 80‚Äì120 ms      | N/A           | N/A             | N/A       | N/A                 |
| **Pattern clustering (100 memories)** | 50‚Äì70 ms       | N/A           | N/A             | N/A       | N/A                 |
| **Background reflection cycle**       | 300‚Äì500 ms     | N/A           | N/A             | N/A       | N/A                 |
| **Cold start latency**                | <100 ms        | ~500 ms       | ~800 ms         | ~200 ms   | ~150 ms             |

### 6.2 Cost Breakdown (Self-Hosted vs Cloud)

#### OpenMemory (Self-Hosted)

| Resource                      | Scale               | Cost/Month       | Notes                                   |
| ----------------------------- | ------------------- | ---------------- | --------------------------------------- |
| **VPS (4 vCPU, 8GB RAM)**     | 100k-500k memories  | $5‚Äì12            | DigitalOcean, Hetzner, Linode           |
| **Storage (SQLite/Postgres)** | 1M memories (~15GB) | $0‚Äì3             | Included in VPS, or S3 at $0.35/GB      |
| **Embeddings (OpenAI)**       | 1M tokens           | $0.13            | text-embedding-3-small                  |
| **Embeddings (Local)**        | Unlimited           | $0               | Ollama/E5/BGE - free                    |
| **Bandwidth**                 | 100GB/month         | $0‚Äì2             | Most VPS include 1-2TB                  |
| **Total (100k memories)**     | ‚Äî                   | **$5‚Äì8/month**   | With local embeddings: **~$5/month**    |
| **Total (1M memories)**       | ‚Äî                   | **$15‚Äì25/month** | With OpenAI: **$18‚Äì25**, Local: **$15** |

#### Competitor Costs (Cloud SaaS)

| Provider        | Scale         | Cost/Month | Limitations                         |
| --------------- | ------------- | ---------- | ----------------------------------- |
| **Zep Cloud**   | 100k memories | $80‚Äì150    | No local embeddings, vendor lock-in |
| **Supermemory** | 100k memories | $60‚Äì120    | Self-host option available          |
| **Mem0**        | 100k memories | $25‚Äì40     | Limited cognitive features          |

### 6.3 Performance Characteristics

#### Query Performance by Operation Type

```
Single memory retrieval:        15-25 ms
HSG multi-sector query (k=8):   110-130 ms
User summary lookup:            5-10 ms (cached)
Pattern clustering (fresh):     50-70 ms
Reflection generation:          300-500 ms
Waypoint traversal (1-hop):     20-30 ms
```

#### Throughput Under Load

| Concurrent Users | Queries/sec | Avg Latency | 95th %ile | Notes                    |
| ---------------- | ----------- | ----------- | --------- | ------------------------ |
| 1                | ~25 ops/s   | 40 ms       | 80 ms     | Single-threaded baseline |
| 10               | ~180 ops/s  | 55 ms       | 120 ms    | Good parallelism         |
| 50               | ~650 ops/s  | 75 ms       | 180 ms    | Near optimal throughput  |
| 100              | ~900 ops/s  | 110 ms      | 280 ms    | CPU-bound, add workers   |

### 6.4 Storage and Scalability

| Scale         | Storage (SQLite) | Storage (Postgres) | RAM Usage  | Query Time |
| ------------- | ---------------- | ------------------ | ---------- | ---------- |
| 10k memories  | ~150 MB          | ~180 MB            | 200-400 MB | 40-60 ms   |
| 100k memories | ~1.5 GB          | ~1.8 GB            | 500 MB-1GB | 110-130 ms |
| 1M memories   | ~15 GB           | ~18 GB             | 1-2 GB     | 180-220 ms |
| 10M memories  | ~150 GB          | ~180 GB            | 4-8 GB     | 300-400 ms |

_Note: With vector compression and mean caching enabled_

### 6.5 Accuracy Benchmarks (LongMemEval)

| System        | Accuracy | P90 Latency | Recall@10 | Precision@10 | Notes                               |
| ------------- | -------- | ----------- | --------- | ------------ | ----------------------------------- |
| OpenMemory    | 94-97%   | 2.1s        | 92%       | 88%          | Multi-sector + waypoint             |
| Zep           | 58-85%   | 3.2s        | 65%       | 62%          | Varies by configuration             |
| Supermemory   | 82%      | 3.1s        | 78%       | 75%          | Claimed, not independently verified |
| Mem0          | 74%      | 2.7s        | 70%       | 68%          | Basic similarity only               |
| Vector DB avg | 60-75%   | 2.4s        | 68%       | 65%          | Without semantic enhancements       |

### 6.6 Cost Comparison Summary

**Monthly Cost at 100k Memories:**

- OpenMemory (self-hosted, local embeddings): **$5‚Äì8**
- OpenMemory (self-hosted, OpenAI embeddings): **$8‚Äì12**
- Zep Cloud: **$80‚Äì150** (10-20√ó more expensive)
- Supermemory SaaS: **$60‚Äì120** (8-15√ó more expensive)
- Mem0: **$25‚Äì40** (3-5√ó more expensive)

**Key Advantages:**

- ‚úÖ **2.5‚Äì3√ó faster queries** than cloud alternatives
- ‚úÖ **10‚Äì20√ó cost reduction** with self-hosting
- ‚úÖ **Zero vendor lock-in** - full data ownership
- ‚úÖ **Local embedding support** - $0 embedding costs
- ‚úÖ **Native multi-user** - automatic summaries included
- ‚úÖ **Cognitive architecture** - decay, reflection, pattern recognition

---

## 7. Security and Privacy

- Bearer authentication required for write APIs
- Optional AES-GCM content encryption
- PII scrubbing and anonymization hooks
- Tenant isolation for multi-user deployments
- Full erasure via `DELETE /memory/:id` or `/memory/delete_all?tenant=X`
- No vendor data exposure; 100% local control

---

## 8. Roadmap

| Phase | Focus                                          | Status         |
| ----- | ---------------------------------------------- | -------------- |
| v1.0  | Core HMD backend (multi-sector memory)         | ‚úÖ Complete    |
| v1.1  | Pluggable vector backends (pgvector, Weaviate) | ‚úÖ Complete    |
| v1.2  | Dashboard (React) + metrics                    | ‚è≥ In progress |
| v1.3  | Learned sector classifier (Tiny Transformer)   | üîú Planned     |
| v1.4  | Federated multi-node mode                      | üîú Planned     |

---

## 9. Contributing

Contributions are welcome.  
See `CONTRIBUTING.md`, `GOVERNANCE.md`, and `CODE_OF_CONDUCT.md` for guidelines.

```bash
make build
make test
```

### Our Contributers:

<!-- readme: contributors -start -->
<table>
	<tbody>
		<tr>
            <td align="center">
                <a href="https://github.com/nullure">
                    <img src="https://avatars.githubusercontent.com/u/81895400?v=4" width="100;" alt="nullure"/>
                    <br />
                    <sub><b>Morven</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/DKB0512">
                    <img src="https://avatars.githubusercontent.com/u/23116307?v=4" width="100;" alt="DKB0512"/>
                    <br />
                    <sub><b>Devarsh (DKB) Bhatt</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/msris108">
                    <img src="https://avatars.githubusercontent.com/u/43115330?v=4" width="100;" alt="msris108"/>
                    <br />
                    <sub><b>Sriram M</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/recabasic">
                    <img src="https://avatars.githubusercontent.com/u/102372274?v=4" width="100;" alt="recabasic"/>
                    <br />
                    <sub><b>Elvoro</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/DoKoB0512">
                    <img src="https://avatars.githubusercontent.com/u/123281216?v=4" width="100;" alt="DoKoB0512"/>
                    <br />
                    <sub><b>DoKoB0512</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/jasonkneen">
                    <img src="https://avatars.githubusercontent.com/u/502002?v=4" width="100;" alt="jasonkneen"/>
                    <br />
                    <sub><b>Jason Kneen</b></sub>
                </a>
            </td>
		</tr>
		<tr>
            <td align="center">
                <a href="https://github.com/muhammad-fiaz">
                    <img src="https://avatars.githubusercontent.com/u/75434191?v=4" width="100;" alt="muhammad-fiaz"/>
                    <br />
                    <sub><b>Muhammad Fiaz</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/pc-quiknode">
                    <img src="https://avatars.githubusercontent.com/u/126496711?v=4" width="100;" alt="pc-quiknode"/>
                    <br />
                    <sub><b>Peter Chung</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/ammesonb">
                    <img src="https://avatars.githubusercontent.com/u/2522710?v=4" width="100;" alt="ammesonb"/>
                    <br />
                    <sub><b>Brett Ammeson</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/Dhravya">
                    <img src="https://avatars.githubusercontent.com/u/63950637?v=4" width="100;" alt="Dhravya"/>
                    <br />
                    <sub><b>Dhravya Shah</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/josephgoksu">
                    <img src="https://avatars.githubusercontent.com/u/6523823?v=4" width="100;" alt="josephgoksu"/>
                    <br />
                    <sub><b>Joseph Goksu</b></sub>
                </a>
            </td>
            <td align="center">
                <a href="https://github.com/lwsinclair">
                    <img src="https://avatars.githubusercontent.com/u/2829939?v=4" width="100;" alt="lwsinclair"/>
                    <br />
                    <sub><b>Lawrence Sinclair</b></sub>
                </a>
            </td>
		</tr>
	<tbody>
</table>
<!-- readme: contributors -end -->

---

## 10. License

MIT License.  
Copyright (c) 2025 OpenMemory.

---

## üë• Community

Join our [Discord](https://discord.gg/P7HaRayqTh) community to connect, share ideas, and take part in exciting discussions!

---

## 11. Check out our other projects

# PageLM: PageLM is a community-driven version of NotebookLM & an education platform that transforms study materials into interactive resources like quizzes, flashcards, notes, and podcasts.

Link: https://github.com/CaviraOSS/PageLM

### Positioning Statement

OpenMemory aims to become the **standard open-source memory layer for AI agents and assistants** ‚Äî combining persistent semantic storage, graph-based recall, and explainability in a system that runs anywhere.

It bridges the gap between vector databases and cognitive memory systems, delivering **high-recall reasoning at low cost** ‚Äî a foundation for the next generation of intelligent, memory-aware AI.
