# ============================================
# OpenMemory - Environment Configuration
# ============================================

# --------------------------------------------
# Backend Server Settings
# --------------------------------------------
OM_PORT=8080
OM_API_KEY=your-secret-api-key-here
OM_MODE=standard # standard | langgraph

# --------------------------------------------
# Metadata Store
# --------------------------------------------
# sqlite (default) | postgres
OM_METADATA_BACKEND=sqlite
OM_DB_PATH=./data/openmemory.sqlite

# PostgreSQL Settings (used when OM_METADATA_BACKEND=postgres or OM_VECTOR_BACKEND=pgvector)
OM_PG_HOST=localhost
OM_PG_PORT=5432
OM_PG_DB=openmemory
OM_PG_USER=postgres
OM_PG_PASSWORD=postgres
OM_PG_SCHEMA=public
OM_PG_TABLE=openmemory_memories
OM_PG_SSL=disable # disable | require

# --------------------------------------------
# Vector Store Backend
# --------------------------------------------
# sqlite (default) | pgvector | weaviate
OM_VECTOR_BACKEND=sqlite
OM_VECTOR_TABLE=openmemory_vectors
OM_WEAVIATE_URL=
OM_WEAVIATE_API_KEY=
OM_WEAVIATE_CLASS=OpenMemory

# --------------------------------------------
# Embeddings Configuration
# --------------------------------------------
# Available providers: openai, gemini, ollama, local, synthetic
OM_EMBEDDINGS=openai
OM_VEC_DIM=1536

# Embedding Mode
# simple   = 1 unified batch call for all sectors (faster, rate-limit safe, recommended)
# advanced = 5 separate calls, one per sector (higher precision, more API calls)
OM_EMBED_MODE=simple

# Advanced Mode Options (only used when OM_EMBED_MODE=advanced)
# Enable parallel embedding (not recommended for Gemini due to rate limits)
OM_ADV_EMBED_PARALLEL=false
# Delay between embeddings in milliseconds
OM_EMBED_DELAY_MS=200

# OpenAI-compatible Embeddings Provider
# OM_OPENAI_BASE_URL=https://api.openai.com/v1
# Model override for all sector embeddings (leave empty to use defaults)
# OM_OPENAI_MODEL=text-embedding-qwen3-embedding-4b

# API Configuration
# Max request body size in bytes (default: 1MB)
OM_MAX_PAYLOAD_SIZE=1000000

# --------------------------------------------
# Embedding Provider API Keys
# --------------------------------------------
# OpenAI Embeddings
OPENAI_API_KEY=your-openai-api-key-here

# Google Gemini Embeddings
GEMINI_API_KEY=your-gemini-api-key-here

# Ollama Local Embeddings
OLLAMA_URL=http://localhost:11434

# Local Model Path (for custom embedding models)
LOCAL_MODEL_PATH=/path/to/your/local/model

# --------------------------------------------
# Memory System Settings
# --------------------------------------------
OM_MIN_SCORE=0.3
OM_DECAY_LAMBDA=0.02

# Brain Sector Configuration (auto-classified, but you can override)
# Sectors: episodic, semantic, procedural, emotional, reflective

# --------------------------------------------
# LangGraph Integration Mode (LGM)
# --------------------------------------------
OM_LG_NAMESPACE=default
OM_LG_MAX_CONTEXT=50
OM_LG_REFLECTIVE=true

# ============================================
# Frontend Dashboard Settings
# ============================================

# Dashboard API URL (connects to backend)
VITE_DASHBOARD_API=http://localhost:3001/api
VITE_BACKEND_API=http://localhost:8080

# Dashboard Server Port
DASHBOARD_PORT=3001

# --------------------------------------------
# Authentication Settings
# --------------------------------------------
# Set to 'true' to enable authentication, 'false' to disable
VITE_AUTH_ENABLED=false

# Better Auth Configuration (only needed if auth is enabled)
# Generate a secure random string for BETTER_AUTH_SECRET
# You can use: openssl rand -base64 32
BETTER_AUTH_SECRET=your-secret-key-here
BETTER_AUTH_URL=http://localhost:3001

# --------------------------------------------
# Real-time Updates
# --------------------------------------------
# Auto-refresh interval in milliseconds (default: 5000ms = 5 seconds)
VITE_AUTO_REFRESH_INTERVAL=5000

