# ============================================
# OpenMemory - Environment Configuration
# ============================================

# --------------------------------------------
# Backend Server Settings
# --------------------------------------------
OM_PORT=8080

# API Authentication (IMPORTANT: Set a strong API key for production!)
# Generate a secure key: openssl rand -base64 32
# Leave empty to disable authentication (development only)
OM_API_KEY=your-secret-api-key-here

# Rate Limiting
# Enable rate limiting to prevent abuse
OM_RATE_LIMIT_ENABLED=true
# Time window in milliseconds (default: 60000 = 1 minute)
OM_RATE_LIMIT_WINDOW_MS=60000
# Maximum requests per window (default: 100 requests per minute)
OM_RATE_LIMIT_MAX_REQUESTS=100

# Optional: Log all authenticated requests (set to 'true' for debugging)
OM_LOG_AUTH=false

# Server Mode
OM_MODE=standard # standard | langgraph

# --------------------------------------------
# Metadata Store
# --------------------------------------------
# sqlite (default) | postgres
OM_METADATA_BACKEND=sqlite
OM_DB_PATH=./data/openmemory.sqlite

# PostgreSQL Settings (used when OM_METADATA_BACKEND=postgres or OM_VECTOR_BACKEND=pgvector)
OM_PG_HOST=localhost
OM_PG_PORT=5432
OM_PG_DB=openmemory
OM_PG_USER=postgres
OM_PG_PASSWORD=postgres
OM_PG_SCHEMA=public
OM_PG_TABLE=openmemory_memories
OM_PG_SSL=disable # disable | require

# --------------------------------------------
# Vector Store Backend
# --------------------------------------------
# sqlite (default) | pgvector | weaviate
OM_VECTOR_BACKEND=sqlite
OM_VECTOR_TABLE=openmemory_vectors
OM_WEAVIATE_URL=
OM_WEAVIATE_API_KEY=
OM_WEAVIATE_CLASS=OpenMemory

# --------------------------------------------
# Embeddings Configuration
# --------------------------------------------
# Available providers: openai, gemini, ollama, local, synthetic
# Embedding models per sector can be configured in models.yaml
OM_EMBEDDINGS=openai
OM_VEC_DIM=1536

# Embedding Mode
# simple   = 1 unified batch call for all sectors (faster, rate-limit safe, recommended)
# advanced = 5 separate calls, one per sector (higher precision, more API calls)
OM_EMBED_MODE=simple

# Advanced Mode Options (only used when OM_EMBED_MODE=advanced)
# Enable parallel embedding (not recommended for Gemini due to rate limits)
OM_ADV_EMBED_PARALLEL=false
# Delay between embeddings in milliseconds
OM_EMBED_DELAY_MS=200

# OpenAI-compatible Embeddings Provider
# OM_OPENAI_BASE_URL=https://api.openai.com/v1
# Model override for all sector embeddings (leave empty to use defaults)
# OM_OPENAI_MODEL=text-embedding-qwen3-embedding-4b

# API Configuration
# Max request body size in bytes (default: 1MB)
OM_MAX_PAYLOAD_SIZE=1000000

# --------------------------------------------
# Embedding Provider API Keys
# --------------------------------------------
# OpenAI Embeddings
OPENAI_API_KEY=your-openai-api-key-here

# Google Gemini Embeddings
GEMINI_API_KEY=your-gemini-api-key-here

# Ollama Local Embeddings
OLLAMA_URL=http://localhost:11434

# Local Model Path (for custom embedding models)
LOCAL_MODEL_PATH=/path/to/your/local/model

# --------------------------------------------
# Memory System Settings
# --------------------------------------------
OM_MIN_SCORE=0.3
OM_DECAY_LAMBDA=0.02

# Decay interval in minutes
# Testing: 0.5 (30s) for rapid benchmarks
# Development: 5 (5min) for realistic decay testing
# Production: 1440 (24h) for stable long-term operation
# Recommended: 5-60 minutes to balance decay accuracy vs overhead
OM_DECAY_INTERVAL_MINUTES=144

# Brain Sector Configuration (auto-classified, but you can override)
# Sectors: episodic, semantic, procedural, emotional, reflective

# Auto-Reflection System
# Automatically creates reflective memories by clustering similar memories
OM_AUTO_REFLECT=false
# Reflection interval in minutes (default: 10)
OM_REFLECT_INTERVAL=10
# Minimum memories required before reflection runs (default: 20)
OM_REFLECT_MIN_MEMORIES=20

# Compression
# Enable automatic content compression for large memories
OM_COMPRESSION_ENABLED=false
# Minimum content length (characters) to trigger compression (default: 100)
OM_COMPRESSION_MIN_LENGTH=100
# Compression algorithm: semantic, syntactic, aggressive, auto (default: auto)
OM_COMPRESSION_ALGORITHM=auto

# --------------------------------------------
# LangGraph Integration Mode (LGM)
# --------------------------------------------
OM_LG_NAMESPACE=default
OM_LG_MAX_CONTEXT=50
OM_LG_REFLECTIVE=true